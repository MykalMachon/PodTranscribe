> *On Hiatus*
> 
> I had a working version of this going locally, deployed it to my homelab, and realized that it needed ~12gb of RAM, 5gb of GDDR5, and 8 cores to do transcriptions ðŸ˜…ðŸ¤¯
> If I find a way to make it more efficient without a significant drop in caption quality, I will give it another go.  

# PodTranscribe
a tool for transcribing podcasts as they're released, and providing a search index
